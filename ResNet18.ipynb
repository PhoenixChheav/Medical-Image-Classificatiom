{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kvvWW-OlP-vN",
   "metadata": {
    "id": "kvvWW-OlP-vN"
   },
   "outputs": [],
   "source": [
    "#Install medmnist package for first run\n",
    "#pip install medmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad895f-c403-421a-9935-eea6d3742dc3",
   "metadata": {
    "id": "10ad895f-c403-421a-9935-eea6d3742dc3"
   },
   "source": [
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc6cb39-f85d-44c3-9e77-014980083721",
   "metadata": {
    "id": "2cc6cb39-f85d-44c3-9e77-014980083721"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from enum import unique\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import medmnist\n",
    "from medmnist import Evaluator\n",
    "from medmnist import INFO, BreastMNIST, ChestMNIST, PneumoniaMNIST\n",
    "from medmnist.evaluator import Evaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_ee7CVqcSclq",
   "metadata": {
    "id": "_ee7CVqcSclq"
   },
   "source": [
    "Performs EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "M5oLjpF2Sedf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5oLjpF2Sedf",
    "outputId": "1dd62d4e-bfe6-4ce1-b647-b12174d7357b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- EDA for Breastmnist -----\n",
      "Task Type: binary-class\n",
      "Number of Channels: 1\n",
      "Training Samples: 546\n",
      "Validation Samples: 78\n",
      "Testing Samples: 156\n",
      "Label Info: {'0': 'malignant', '1': 'normal, benign'}\n",
      "\n",
      "\n",
      "----- EDA for Pneumoniamnist -----\n",
      "Task Type: binary-class\n",
      "Number of Channels: 1\n",
      "Training Samples: 4708\n",
      "Validation Samples: 524\n",
      "Testing Samples: 624\n",
      "Label Info: {'0': 'normal', '1': 'pneumonia'}\n",
      "\n",
      "\n",
      "----- EDA for Chestmnist -----\n",
      "Task Type: multi-label, binary-class\n",
      "Number of Channels: 1\n",
      "Training Samples: 78468\n",
      "Validation Samples: 11219\n",
      "Testing Samples: 22433\n",
      "Label Info: {'0': 'atelectasis', '1': 'cardiomegaly', '2': 'effusion', '3': 'infiltration', '4': 'mass', '5': 'nodule', '6': 'pneumonia', '7': 'pneumothorax', '8': 'consolidation', '9': 'edema', '10': 'emphysema', '11': 'fibrosis', '12': 'pleural', '13': 'hernia'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phoen\\AppData\\Local\\Temp\\ipykernel_22212\\1913655361.py:32: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = plt.cm.get_cmap('tab20')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#list of datasets to be used for training and evaluation\n",
    "dataset_names = ['breastmnist', 'pneumoniamnist', 'chestmnist']\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    #Performs basic EDA on MedMNIST datasets\n",
    "    print(f'----- EDA for {dataset_name.capitalize()} -----')\n",
    "    info = INFO[dataset_name]\n",
    "    task = info['task']\n",
    "    sample = info['n_samples']\n",
    "    n_channels = info['n_channels']\n",
    "    dataset_train = sample['train']\n",
    "    dataset_val = sample['val']\n",
    "    dataset_test = sample['test']\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "    temp_dataset = DataClass(split = 'train', transform = transforms.ToTensor(), download = True)\n",
    "    train_labels = temp_dataset.labels\n",
    "\n",
    "\n",
    "    # print(f'{info}')\n",
    "    print(f'Task Type: {task}')\n",
    "    print(f'Number of Channels: {n_channels}')\n",
    "    print(f'Training Samples: {dataset_train}')\n",
    "    print(f'Validation Samples: {dataset_val}')\n",
    "    print(f'Testing Samples: {dataset_test}')\n",
    "    print(f'Label Info: {info[\"label\"]}\\n\\n')\n",
    "\n",
    "    if len(info[\"label\"]) > 2:\n",
    "        labels_counts = np.sum(train_labels, axis = 0)\n",
    "\n",
    "        #Use color map\n",
    "        cmap = plt.cm.get_cmap('tab20')\n",
    "        colors = cmap(np.arange(len(info[\"label\"])))\n",
    "\n",
    "        labels = [info['label'][str(i)] for i in range(len(info[\"label\"]))]\n",
    "\n",
    "        #Plot bar plot for multi-class\n",
    "        plt.bar(labels, labels_counts, color = colors)\n",
    "        plt.title(f\"{dataset_name.capitalize()} - Label Distribution\")\n",
    "        plt.xlabel(\"Labels\")\n",
    "        plt.ylabel(\"Number of Positive Samples\")\n",
    "        #Vertical label\n",
    "        plt.xticks(rotation = 45, ha = 'right')\n",
    "    else:\n",
    "        unique_labels, counts = np.unique(train_labels, return_counts = True)\n",
    "        labels = [info['label'][str(i)] for i in range(len(unique_labels))]\n",
    "\n",
    "        #plot bar plot\n",
    "        colors = ['orange', 'blue']\n",
    "        plt.bar(labels, counts, color = colors)\n",
    "        plt.title(f\"{dataset_name.capitalize()} - Label Distribution\")\n",
    "        plt.xlabel(\"Class Labels\")\n",
    "        plt.ylabel(\"Number of Samples\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'figures/{dataset_name} bar.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a0bb6-ede9-40d5-b24e-32f7f59790a0",
   "metadata": {
    "id": "758a0bb6-ede9-40d5-b24e-32f7f59790a0"
   },
   "source": [
    "### Valitaion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd567ad1-2824-4de2-b5c1-1fc89c3dea2b",
   "metadata": {
    "id": "bd567ad1-2824-4de2-b5c1-1fc89c3dea2b"
   },
   "outputs": [],
   "source": [
    "### Valiation\n",
    "def calculate_validation_metrics(model, val_load, device, dataset_name):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([])\n",
    "    y_score = torch.tensor([])\n",
    "\n",
    "    task = INFO[dataset_name]['task']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_load:\n",
    "            outputs = model(inputs.to(device))\n",
    "\n",
    "            if task == 'binary-class':\n",
    "                scores = F.softmax(outputs, dim = 1)\n",
    "            else:\n",
    "                scores = torch.sigmoid(outputs)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets.cpu()), 0)\n",
    "            y_score = torch.cat((y_score, scores.cpu()), 0)\n",
    "\n",
    "    evaluator = Evaluator(dataset_name, split = 'val')\n",
    "    scores_numpy = y_score.numpy()\n",
    "\n",
    "    if task == 'binary-class':\n",
    "        scores_numpy = scores_numpy[:, 1]\n",
    "    val_auc, _ = evaluator.evaluate(scores_numpy)\n",
    "    return val_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0YnOvG6igWc5",
   "metadata": {
    "id": "0YnOvG6igWc5"
   },
   "source": [
    "Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ICrSvIlwgVZ5",
   "metadata": {
    "id": "ICrSvIlwgVZ5"
   },
   "outputs": [],
   "source": [
    "def plot_metrics_for_binary_task(y_true, y_score, dataset_name):\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    # ----- ROC Curve -----\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_score)\n",
    "    calculated_roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label = f'ROC curve (area = {calculated_roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0,1], linestyle = '--', label = 'Random Classifier')\n",
    "    plt.title(f'{dataset_name.capitalize()} ROC Curve')\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'figures/{dataset_name} ROC.png')\n",
    "    plt.close()\n",
    "    # ----- Score Distribution -----\n",
    "    score_class_0 = y_score[y_true == 0]\n",
    "    score_class_1 = y_score[y_true == 1]\n",
    "\n",
    "    plt.hist(score_class_0, bins = 20, alpha = 0.5, density = True, label = 'True Negative Scores (Class 0)')\n",
    "    plt.hist(score_class_1, bins = 20, alpha = 0.5, density = True, label = 'True Positive Scores (Class 1)')\n",
    "    plt.xlabel('Predicted Probability (Score)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'{dataset_name.capitalize()} Score Distribution')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'figures/{dataset_name} score.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_score_distribution(y_true, y_score, dataset_name):\n",
    "    plt.figure(figsize = (12, 8))\n",
    "\n",
    "    scores_class_0 = y_true[y_true == 0]\n",
    "    scores_class_1 = y_score[y_true == 1]\n",
    "\n",
    "    plt.hist(scores_class_0, bins = 20, alpha = 0.6, label = 'True Negative Scores (Class 0)')\n",
    "    plt.hist(scores_class_1, bins = 20, alpha = 0.6, label = 'True Positive Scores (Class 1)')\n",
    "\n",
    "    plt.xlabel('Predicted Probability (Score)')\n",
    "    plt.ylabel('Normalize Frequency (Density)')\n",
    "    plt.title(f'{dataset_name.capitalize()} Score Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'figures/{dataset_name} score.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a4cc0-54be-4169-a747-05787bcde6f9",
   "metadata": {
    "id": "3c5a4cc0-54be-4169-a747-05787bcde6f9"
   },
   "source": [
    "### Training and Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74db804-43c4-44ba-ac7d-8aa5641a32e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e74db804-43c4-44ba-ac7d-8aa5641a32e9",
    "outputId": "d5494107-12ee-4621-a000-cd3cfa6b1b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Training and Evaluation for Breastmnist -----\n",
      "Stats for breastmnist: Mean = 0.3276, Standard Deviation = 0.2057\n",
      "Model Best Val AUC: 0.6483 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.6775 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.7151 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.7678 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.8329 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.8346 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.8630 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.8906 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.8914 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9114 saved to: checkpoints/breastmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9373 saved to: checkpoints/breastmnist_ckpt.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 26.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test AUC: 0.8340, Test ACC: 0.8269\n",
      "model_test architecture created successfully and ready to load weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Loaded Checkpoint: 100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 24.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test AUC: 0.8552\n",
      "Final test ACC: 0.8077\n",
      "\n",
      "\n",
      "----- Training and Evaluation for Pneumoniamnist -----\n",
      "Stats for pneumoniamnist: Mean = 0.5719, Standard Deviation = 0.1684\n",
      "Model Best Val AUC: 0.9791 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9883 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9893 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9920 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9926 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9948 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9951 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9961 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9964 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9966 saved to: checkpoints/pneumoniamnist_ckpt.pth\n",
      "Model Best Val AUC: 0.9969 saved to: checkpoints/pneumoniamnist_ckpt.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test AUC: 0.9575, Test ACC: 0.8526\n",
      "model_test architecture created successfully and ready to load weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Loaded Checkpoint: 100%|█████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 14.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test AUC: 0.9469\n",
      "Final test ACC: 0.8830\n",
      "\n",
      "\n",
      "----- Training and Evaluation for Chestmnist -----\n",
      "Stats for chestmnist: Mean = 0.4936, Standard Deviation = 0.2380\n",
      "Model Best Val AUC: 0.6733 saved to: checkpoints/chestmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.6952 saved to: checkpoints/chestmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.7029 saved to: checkpoints/chestmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.7083 saved to: checkpoints/chestmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.7107 saved to: checkpoints/chestmnist_ckpt.pth\n",
      "Model Best Val AUC: 0.7172 saved to: checkpoints/chestmnist_ckpt.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 176/176 [00:11<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test AUC: 0.6498, Test ACC: 0.9339\n",
      "model_test architecture created successfully and ready to load weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Loaded Checkpoint: 100%|█████████████████████████████████████████████████████| 176/176 [00:10<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test AUC: 0.7054\n",
      "Final test ACC: 0.9470\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#list of datasets to be used for training and evaluation\n",
    "dataset_names = ['breastmnist', 'pneumoniamnist', 'chestmnist']\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"----- Training and Evaluation for {dataset_name.capitalize()} -----\")\n",
    "    ### Define and train model\n",
    "    info = INFO[dataset_name]\n",
    "    task = info['task'] #identifies\n",
    "    n_channels = info['n_channels'] #Number of input channels\n",
    "    n_classes = len(info['label']) #Number of output channels\n",
    "\n",
    "    #dynamic loss function\n",
    "    if task == 'multi-label, binary-class':\n",
    "        crit = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    #Calculate Dataset Statistic for Normalization\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    #Load dataset with ToTensor() to calculate mean and std deviation\n",
    "    temp_dataset = DataClass(split = 'train', transform = transforms.ToTensor(), download = True)\n",
    "    temp_loader = data.DataLoader(temp_dataset, batch_size = len(temp_dataset))\n",
    "    images, _ = next(iter(temp_loader))\n",
    "\n",
    "    dataset_mean = images.mean(dim = [0, 2, 3]).tolist()\n",
    "    dataset_std = images.std(dim = [0, 2, 3]).tolist()\n",
    "\n",
    "    print(f\"Stats for {dataset_name}: Mean = {dataset_mean[0]:.4f}, Standard Deviation = {dataset_std[0]:.4f}\")\n",
    "\n",
    "    ### pre-processing\n",
    "    transformed = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #Normalize data using the calculated mean and std for better model convergence\n",
    "        transforms.Normalize(mean =dataset_mean, std = dataset_std)\n",
    "    ])\n",
    "    #Load actual data\n",
    "    train_dataset = DataClass(split = 'train', transform = transformed, download = True)\n",
    "    val_dataset = DataClass(split = 'val', transform = transformed, download = True)\n",
    "    test_dataset = DataClass(split = 'test', transform = transformed, download = True)\n",
    "\n",
    "    sizes = []\n",
    "    for img, label in train_dataset:\n",
    "        sizes.append(img.numpy().flatten())\n",
    "\n",
    "    all_sizes = np.concatenate(sizes, axis = 0)\n",
    "    bmean = all_sizes.mean()\n",
    "    bstd = all_sizes.std()\n",
    "\n",
    "    #Define dataloader obj\n",
    "    BATCH_SIZE = 128\n",
    "    train_load = data.DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    val_load = data.DataLoader(dataset = val_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "    test_load = data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "    #Model initialization (ResNet-18)\n",
    "    model = models.resnet18(weights = None)\n",
    "    #ajdust the input layer if it's a grayscale img\n",
    "    if n_channels == 1:\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "\n",
    "    #adjust the final fully connected larer for the number of classes\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, n_classes)\n",
    "\n",
    "    #move to device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    #define loss, optim, training loop\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "    NUM_EPOCHS = 30\n",
    "\n",
    "    ### Training data\n",
    "    best_val_auc = float('-inf')\n",
    "    # Initialize lists to store per-epoch data\n",
    "    training_loss = [] # This will now store average loss per epoch\n",
    "    val_auc_list = []  # This already stores AUC per epoch\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        current_epoch_total_loss = 0.0\n",
    "        num_samples_in_epoch = 0\n",
    "        for inputs, targets in train_load:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            #prepare targets based on task\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(device).float() #BCEWithLogitsLoss require float target\n",
    "            else:\n",
    "                targets = targets.to(device).long().squeeze() #CrossEntropyLoss require long target\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = crit(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            current_epoch_total_loss += loss.item() * inputs.size(0)\n",
    "            num_samples_in_epoch += inputs.size(0)\n",
    "\n",
    "        #calculate average loss for the current epoch\n",
    "        if num_samples_in_epoch > 0:\n",
    "            avg_loss_this_epoch = current_epoch_total_loss / num_samples_in_epoch\n",
    "            training_loss.append(avg_loss_this_epoch) # Store average loss per epoch\n",
    "        else:\n",
    "            training_loss.append(0.0) # Handle empty train_load\n",
    "\n",
    "        #validation check\n",
    "        val_auc = calculate_validation_metrics(model, val_load, device, dataset_name)\n",
    "        val_auc_list.append(val_auc) # Store validation AUC per epoch\n",
    "\n",
    "        #save best model based on validation AUC\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            #--------------- Save checkpoint ---------------\n",
    "            save_ckpt = f'checkpoints/{dataset_name}_ckpt.pth'\n",
    "            torch.save(model.state_dict(), save_ckpt)\n",
    "            print(f\"Model Best Val AUC: {val_auc:.4f} saved to: {save_ckpt}\")\n",
    "        model.train()\n",
    "\n",
    "    #evaluation\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([])\n",
    "    y_score = torch.tensor([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_load):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.long().squeeze().to(device)\n",
    "\n",
    "            #get output\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #multi class\n",
    "            # scores = F.softmax(outputs, dim = 1)\n",
    "            scores = torch.sigmoid(outputs)\n",
    "\n",
    "            #collect true label\n",
    "            y_true = torch.cat((y_true, targets.cpu()),0)\n",
    "            y_score = torch.cat((y_score, scores.cpu()),0)\n",
    "\n",
    "    evaluator = Evaluator(dataset_name, split = 'test')\n",
    "    auc_score, acc_score = evaluator.evaluate(y_score.numpy(), save_folder = None, run = False)\n",
    "    print(f\"\\nTest AUC: {auc_score:.4f}, Test ACC: {acc_score:.4f}\")\n",
    "\n",
    "    ### Load the saved checkpoint for another test\n",
    "    #initialize the model architecture (ResNet18)\n",
    "    model_test = models.resnet18(weights = None)\n",
    "\n",
    "    #Adjust first layer for single-channel input\n",
    "    model_test.conv1 = nn.Conv2d(n_channels, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "\n",
    "    #Adjust the final fully connected layer for 2 classes\n",
    "    num_ftrs_test = model_test.fc.in_features\n",
    "    model_test.fc = nn.Linear(num_ftrs, n_classes)\n",
    "\n",
    "    #Move to the appropriate device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_test.to(device)\n",
    "    print(\"model_test architecture created successfully and ready to load weights.\")\n",
    "\n",
    "    #load weights from the best-performing epoch found during validation\n",
    "    model_test.load_state_dict(torch.load(save_ckpt, map_location = device))\n",
    "\n",
    "    y_true_list = []\n",
    "    y_score_list = []\n",
    "    model_test.eval()\n",
    "\n",
    "    #evaluate the best model on test set\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_load, desc = \"Testing Loaded Checkpoint\"):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.long().squeeze().to(device)\n",
    "\n",
    "            #use the loaded model_test instance\n",
    "            outputs = model_test(inputs)\n",
    "\n",
    "            #get probabilities\n",
    "            scores = F.softmax(outputs, dim = 1)\n",
    "\n",
    "            if dataset_name in ['breastmnist', 'pneumoniamnist']:\n",
    "              y_score_list.append(scores.cpu()[:, 1])\n",
    "            elif dataset_name == 'chestmnist':\n",
    "              scores = torch.sigmoid(outputs)\n",
    "              y_score_list.append(scores.cpu())\n",
    "\n",
    "            #collect true label\n",
    "            y_true_list.append(targets.cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true_list, 0)\n",
    "    y_score = torch.cat(y_score_list, 0)\n",
    "\n",
    "    y_true_np = y_true.numpy()\n",
    "    y_score_np = y_score.numpy()\n",
    "\n",
    "    evaluator = Evaluator(dataset_name, split = 'test')\n",
    "\n",
    "    #metrics\n",
    "    auc_score, acc_score = evaluator.evaluate(y_score.numpy())\n",
    "\n",
    "    print(f\"Final test AUC: {auc_score:.4f}\")\n",
    "    print(f\"Final test ACC: {acc_score:.4f}\\n\\n\")\n",
    "\n",
    "    #plot final test result (ROC)\n",
    "    if task == 'binary-class':\n",
    "        plot_metrics_for_binary_task(y_true_np, y_score_np, dataset_name)\n",
    "    else:\n",
    "        plot_score_distribution(y_true_np, y_score_np, dataset_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
